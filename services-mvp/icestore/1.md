## **Raw Data Storage Microservice: Options and Abstraction**

This new microservice will be responsible for consuming raw device data messages (likely from a Pub/Sub topic, potentially the "unidentified device messages" topic, or a new dedicated topic for all raw data intended for audit) and storing this data in a way that is suitable for long-term audit and disaster recovery. Quick accessibility is not a primary concern ("slow recall" is acceptable).

### **Google Cloud Storage Options for MVP (Slow Recall Focus)**

Given the "slow recall" and audit/recovery focus, here are strong contenders within Google Cloud:

1. **Google Cloud Storage (GCS)**
    * **Storage Classes:**
        * **Archive Storage:** This is the lowest-cost GCS storage class, specifically designed for data archiving, online backup, and disaster recovery. Data is typically accessed less than once a year. Retrieval times are in the order of hours, and there are associated retrieval costs. This aligns perfectly with your "slow recall" and audit/recovery needs if access is truly infrequent.
        * **Coldline Storage:** Also very cost-effective for data accessed infrequently (e.g., less than once every 90 days). Retrieval is faster than Archive (sub-second to minutes). This could be a good balance if there's a slightly higher chance of needing to access the audit data within a shorter timeframe than Archive implies.
    * **How it fits:** You can store each raw message (or batches of messages) as an individual object (file) in a GCS bucket. Object names can be structured to include device EUI, timestamps, etc., for organization (e.g., gs://\<your-bucket\>/raw-audit-logs/\<year\>/\<month\>/\<day\>/\<deviceEUI\>-\<messageTimestamp\>.dat).
    * **Pros:**
        * Extremely cost-effective for long-term storage.
        * Highly durable and scalable.
        * Simple to integrate with (Go client libraries are excellent).
        * Data lifecycle management can automatically transition data to colder storage classes or delete it after a defined period.
    * **Cons:**
        * Not suitable for direct querying of the stored data. Data must be retrieved and then processed.
        * Retrieval from Archive/Coldline has costs and latency.
2. **BigQuery (with Long-Term Storage)**
    * **How it fits:** You could stream the raw messages (Device EUI, timestamp, raw payload as BYTES or STRING) into a BigQuery table. BigQuery automatically transitions data in partitions that haven't been modified for 90 days into long-term storage, which is roughly half the cost of active storage.
    * **Pros:**
        * Allows for occasional SQL-based querying directly on the raw data if needed for audit or specific investigations, without a separate retrieval step.
        * Still benefits from reduced storage costs for older data.
        * Scalable and managed.
    * **Cons:**
        * Ingestion costs (streaming inserts) are higher than simply writing files to GCS.
        * Even with long-term storage, it might be more expensive than GCS Archive if the data is truly "cold" and never queried.
        * The primary purpose is analytics, so it might be overkill if you *only* need archival.

**Recommendation for MVP:**

**Google Cloud Storage (GCS) using the Archive or Coldline storage class** is likely the most direct and cost-effective fit for your stated MVP requirements of "slow recall, audit, and recovery." It's simple to implement for raw data dumps.

### **Abstraction Strategy**

To allow for future flexibility (e.g., moving to a different cloud provider or a different storage mechanism like Kafka for archival streams if requirements change), we should define an interface for this raw data storage.

Let's define an interface, say RawDataArchiver:

package archivalstorage // Or a more specific package name

import (  
"context"  
"time"  
)

// RawDeviceData represents the essential information to be archived.  
type RawDeviceData struct {  
DeviceEUI          string    \`json:"device\_eui"\`  
RawPayload         \[\]byte    \`json:"raw\_payload"\` // The actual raw bytes  
MessageTimestamp   time.Time \`json:"message\_timestamp"\` // Timestamp from the original message source  
SourceTopic        string    \`json:"source\_topic,omitempty"\` // e.g., the Pub/Sub topic it came from  
IngestionTimestamp time.Time \`json:"ingestion\_timestamp"\`    // When this archival service processed it  
// You can add other metadata relevant for audit, like message ID from the broker, etc.  
}

// RawDataArchiver defines the interface for storing raw device data.  
type RawDataArchiver interface {  
// Archive stores the provided raw device data.  
Archive(ctx context.Context, data RawDeviceData) error  
// Stop allows the archiver to perform any cleanup, like flushing buffers or closing connections.  
Stop() error  
}

**Implementation with GCS:**

A GCSDataArchiver would implement this interface:

* Its Archive method would:
    1. Construct an object name (e.g., based on DeviceEUI and MessageTimestamp).
    2. Use the GCS client library to upload the data.RawPayload (potentially after serializing the whole RawDeviceData struct to JSON or another format if you want to store the metadata alongside the payload in the same object) to the designated GCS bucket and storage class.
* Its Stop method might not need to do much for GCS if writes are direct, but could be used if you implement batching.

This abstraction allows you to write the core logic of your new microservice (consuming from Pub/Sub, preparing RawDeviceData) independently of the specific storage backend. In your main.go, you'd then instantiate the concrete implementation (e.g., GCSDataArchiver) and inject it into your service.

### **Next Steps (as per your plan):**

1. **Decide on the Storage Mechanism for MVP:** Based on the above, GCS Archive/Coldline seems like a strong candidate.
2. **Unit Test It:** We'll define the concrete GCS implementation and unit test its Archive method (likely by mocking the GCS client library or using a fake in-memory GCS for testing if available, though mocking the client is more common).
3. **Mock It:** Create a mock implementation of RawDataArchiver for testing the service that uses it.
4. **Build the Service:** Develop the microservice that consumes from Pub/Sub and uses the RawDataArchiver interface.

What are your thoughts on these options, particularly GCS for the MVP? Once you've decided, we can move to defining the GCS implementation and its tests.